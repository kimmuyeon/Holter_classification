{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.data_loader import load_data\n",
    "from models.attention_ae import AttentionAE\n",
    "from models.mil_model import SimpleMIL\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import MSELoss, BCELoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR         = './data'\n",
    "LEADS            = [0, 1, 2]\n",
    "SEG_SEC          = 10\n",
    "BATCH_AE         = 64\n",
    "EPOCH_AE         = 10\n",
    "BATCH_MIL        = 1\n",
    "EPOCH_MIL        = 5\n",
    "ATTN_TH_VALUES   = np.linspace(0.1, 0.9, 9)\n",
    "device           = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_bags, train_labels, test_bags, test_labels = load_data(\n",
    "    DATA_DIR, LEADS, SEG_SEC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AttentionAE(input_dim=SEG_SEC * len(LEADS), latent_dim=8).to(device)\n",
    "opt_ae = Adam(ae.parameters(), lr=1e-4)\n",
    "crit_ae = MSELoss()\n",
    "\n",
    "# Flatten all instances for AE training\n",
    "all_instances = np.concatenate(train_bags, axis=0)\n",
    "instances_tensor = torch.tensor(\n",
    "    all_instances.reshape(len(all_instances), -1),\n",
    "    dtype=torch.float32\n",
    ").to(device)\n",
    "ae_dataset = torch.utils.data.TensorDataset(instances_tensor)\n",
    "ae_loader  = DataLoader(ae_dataset, batch_size=BATCH_AE, shuffle=True)\n",
    "\n",
    "for epoch in range(1, EPOCH_AE + 1):\n",
    "    ae.train()\n",
    "    total_loss = 0\n",
    "    for (x_batch,) in ae_loader:\n",
    "        recon, _ = ae(x_batch)\n",
    "        loss = crit_ae(recon, x_batch)\n",
    "        opt_ae.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_ae.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"[AE] Epoch {epoch}/{EPOCH_AE}, Loss: {total_loss/len(ae_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_bag(ae_model, bag, threshold):\n",
    "    ae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(\n",
    "            bag.reshape(len(bag), -1),\n",
    "            dtype=torch.float32\n",
    "        ).to(device)\n",
    "        _, scores = ae_model(X)         # [N,1]\n",
    "        mask = (scores.squeeze() >= threshold).cpu().numpy()\n",
    "        selected = bag[mask]\n",
    "        # Ensure at least one instance\n",
    "        if len(selected) == 0:\n",
    "            idx = scores.squeeze().argmax().item()\n",
    "            selected = bag[idx:idx+1]\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for th in ATTN_TH_VALUES:\n",
    "    # Select instances for each bag\n",
    "    sel_train = [select_bag(ae, b, th) for b in train_bags]\n",
    "    sel_test  = [select_bag(ae, b, th) for b in test_bags]\n",
    "\n",
    "    # Train MIL Model\n",
    "    mil = SimpleMIL(input_dim=SEG_SEC * len(LEADS)).to(device)\n",
    "    opt_mil = Adam(mil.parameters(), lr=1e-4)\n",
    "    crit_mil = BCELoss()\n",
    "\n",
    "    for _ in range(EPOCH_MIL):\n",
    "        mil.train()\n",
    "        for bag, label in zip(sel_train, train_labels):\n",
    "            bag_tensor = torch.tensor(\n",
    "                bag.reshape(len(bag), -1),\n",
    "                dtype=torch.float32\n",
    "            ).to(device)\n",
    "            pred = mil(bag_tensor).squeeze()\n",
    "            loss = crit_mil(pred, torch.tensor(label, dtype=torch.float32).to(device))\n",
    "            opt_mil.zero_grad()\n",
    "            loss.backward()\n",
    "            opt_mil.step()\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    mil.eval()\n",
    "    correct = 0\n",
    "    for bag, label in zip(sel_test, test_labels):\n",
    "        bag_tensor = torch.tensor(\n",
    "            bag.reshape(len(bag), -1),\n",
    "            dtype=torch.float32\n",
    "        ).to(device)\n",
    "        p = (mil(bag_tensor).item() >= 0.5)\n",
    "        correct += (p == bool(label))\n",
    "    accuracy = correct / len(test_labels)\n",
    "    results.append((th, accuracy))\n",
    "    print(f\"Threshold {th:.2f} â†’ Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds, accuracies = zip(*results)\n",
    "plt.figure()\n",
    "plt.plot(thresholds, accuracies)\n",
    "plt.xlabel('Attention Threshold')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Threshold Tuning Results')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
